{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Five Minutes With AI: Whisper\n",
        "\n",
        "Today we are going to use a very new, very accurate, very useful new speech recognizer called [Whisper](https://openai.com/blog/whisper/).\n",
        "\n"
      ],
      "metadata": {
        "id": "usmXbpFv7Yxs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Before we get started, what even is this thing you are showing me?\n",
        "\n"
      ],
      "metadata": {
        "id": "7q4m-A4C9Npp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a *jupyter notebook*. It works like a lab book (in the natural sciences). \n",
        "\n",
        "A notebook is a list of *cells*. Each cell can be one of:\n",
        "* code - in this case, python code\n",
        "* mark down - text: your thoughts about what you are doing\n",
        "\n",
        "To \"execute\" (run) a code cell, use Shift+Enter (hold down the Shift and Enter keys at once). \n",
        "\n",
        "If you'd like help with notebooks, we are here."
      ],
      "metadata": {
        "id": "FGAtfhPgD6zL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Why do you like Whisper?\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GsWYE-abB_wf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here are some things we like about Whisper:\n",
        "* It can be used to transcribe speech of varying length.\n",
        "* It is **very accurate**.\n",
        "* It is pretty fast.\n",
        "* It is **multilingual**!\n",
        "* You don't need to first become a computer scientist and figure out how to get your speech into the right \"shape\"; some thoughtful engineers have done that already.\n"
      ],
      "metadata": {
        "id": "ijGQ4XucDz7B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What do you not like about Whisper?\n",
        "\n"
      ],
      "metadata": {
        "id": "EzJ3qCorCC_N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here are some things we don't like about Whisper:\n",
        "* It outputs transcripts in ~30 second segments. So it might cut off the speaker mid-turn, mid-utterance or mid-word.\n",
        "* It does not provide phone- or word-level time alignments. So if you need that, this is not for you (but we know of things that might work for you! Come see us!).\n",
        "* It does run faster on GPUs.\n",
        "* In the [preprint describing Whisper](https://arxiv.org/pdf/2212.04356.pdf), the authors say they trained on 680,000 hours of speech+text collected from the internet. However, they don't indicate *which speech*, *from where*, *transcribed by whom*, or *with whose consent*. It's possible, for example, that they collected all the audio books from Audible (with or without consent) or speeches from Colby. \n",
        "\n",
        "[AI researchers really, really, really, really, really need to learn how to be more careful with data and more clearly document the sources, nature and permissions in data they use.]\n"
      ],
      "metadata": {
        "id": "Wt6A9okqD2ia"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tell me more about how Whisper works\n",
        "\n"
      ],
      "metadata": {
        "id": "g-Uu5VFKCGfj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Whisper uses **transformer** models (just like DALL-E, ChatGPT, etc). In the case of Whisper, the models are trained on 30-second chunks of speech. The input is the speech chunk (transformed into a special kind of representation called a log-Mel spectrogram, so that it can be treated kind of like a picture!) and the output is the transcript. \n",
        "\n",
        "Whisper comes with multiple *models* (any modern AI will be a code shell plus one or more model fillings, just like a pie pan can be filled with multiple kinds of pie). [Here](https://github.com/openai/whisper/blob/main/model-card.md) they are. Today we will use the English \"base\" model which does pretty well on English."
      ],
      "metadata": {
        "id": "IKz3HNZID4uX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Okay, let's get to it!"
      ],
      "metadata": {
        "id": "EIBrJ-wfEAov"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### First, we install whisper."
      ],
      "metadata": {
        "id": "fFv3wpia9H_5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbOeeMMH7Xly",
        "outputId": "40a7191c-d850-45c6-974a-a23244521669"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai-whisper\n",
            "  Downloading openai-whisper-20230124.tar.gz (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from openai-whisper) (1.21.6)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from openai-whisper) (1.13.1+cu116)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from openai-whisper) (4.64.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.8/dist-packages (from openai-whisper) (9.0.0)\n",
            "Collecting transformers>=4.19.0\n",
            "  Downloading transformers-4.26.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpeg-python==0.2.0\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.8/dist-packages (from ffmpeg-python==0.2.0->openai-whisper) (0.16.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->openai-whisper) (2022.6.2)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.12.0-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->openai-whisper) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->openai-whisper) (2.25.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->openai-whisper) (3.9.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->openai-whisper) (21.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch->openai-whisper) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers>=4.19.0->openai-whisper) (3.0.9)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=4.19.0->openai-whisper) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=4.19.0->openai-whisper) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=4.19.0->openai-whisper) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=4.19.0->openai-whisper) (4.0.0)\n",
            "Building wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20230124-py3-none-any.whl size=1179329 sha256=966ca5f77b8a1095d3982a9e60b69a6a03561590812234944a30398f431d15ed\n",
            "  Stored in directory: /root/.cache/pip/wheels/48/c2/dd/8639c7cda1e20412e499ab65e5003d8863ef8622792ea26446\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: tokenizers, ffmpeg-python, huggingface-hub, transformers, openai-whisper\n",
            "Successfully installed ffmpeg-python-0.2.0 huggingface-hub-0.12.0 openai-whisper-20230124 tokenizers-0.13.2 transformers-4.26.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -U openai-whisper\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Second, we use whisper to recognize some speech\n",
        "\n",
        "For this purpose, we need an audio file! I will use a recording of Martin Luther King's most famous speech, downloaded from [here](https://ia800207.us.archive.org/29/items/MLKDream/MLKDream.wav)."
      ],
      "metadata": {
        "id": "XU0wT8dU94aR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "\n",
        "model = whisper.load_model(\"base.en\")\n",
        "result = model.transcribe(\"https://ia800207.us.archive.org/29/items/MLKDream/MLKDream.wav\")\n",
        "print(result[\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4khFEBTi93t7",
        "outputId": "1c1a19fe-ff57-4b7d-aea7-266983b765c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████| 139M/139M [00:02<00:00, 53.7MiB/s]\n",
            "/usr/local/lib/python3.8/dist-packages/whisper/transcribe.py:78: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " I have the pleasure to present to you Dr. Martin Luther King, Jr. I am happy to join with you today in what will go down in history as the greatest demonstration for freedom in the history of our nation. Five score years ago, a great American in whose symbolic shadow we stand today signed the Emancipation Proclamation. This momentous decree came as a great beacon light of hope to millions of Negro slaves who had been seared in the flames of withering injustice. It came as a joyous daybreak to end the long night of their captivity. But one hundred years later, the Negro still is not free. One hundred years later, the life of the Negro is still sadly crippled by the manacles of segregation and the chains of discrimination. One hundred years later, the Negro lives on a lonely island of poverty in the midst of a vast ocean of material prosperity. One hundred years later, the Negro is still languished in the corners of American society and finds himself in exile in his own land. And so we've come here today to dramatize a shameful condition. In a sense, we've come to our nation's capital to cash a check. When the architects of our republic wrote the magnificent words of the Constitution and the Declaration of Independence, they were signing a promise or a note to which every American was to fall out. This note was a promise at all men. Yes, black men as well as white men would be guaranteed the unalienable rights of life, liberty, and the pursuit of happiness. It is obvious today that America has defaulted on this promise or a note insofar as her citizens of color are concerned. Instead of honoring this sacred obligation, America has given the Negro people a bad check, a check which has come back marked insufficient funds. But we refuse to believe that the Bank of Justice is bankrupt. We refuse to believe that our insufficient funds and the great bolts of opportunity of this nation. So we've come to cash this check, a check that will give us upon demand the riches of freedom and the security of justice. We have also come to this hallowed spot to remind America of the fierce urgency of now. This is no time to engage in the luxury of cooling off or to take the tranquilizing drug of bradualism. Now is the time to make real the promises of democracy. Now is the time to rise from the dark and desolate valley of segregation to the sunlit path of racial justice. Now is the time to lift our nation from the quick sands of racial injustice to the solid rocker brotherhood. Now is the time to make justice a reality for all of God's children. It would be fatal for the nation to overlook the urgency of the moment. This sweltering sum of the Negro's legitimate discontent will not pass until that is an invigorating autumn of freedom and equality. 1963 is not an end but a beginning. Those who hope that the Negro needed to blow off steam and will now be content will have a rude awakening if the nation returns to business as usual. There will be neither rest nor tranquility in America until the Negroes granted his citizenship rights. The whirlwinds are revolt will continue to shake the foundations of our nation until the bright day of justice emerges. But that is something that I must say to my people who stand on the wrong threshold which leads into the palace of justice in the process of gaining our rightful place. We must not be guilty of wrongful deeds. Let us not seek to satisfy our thirst for freedom by drinking from the cup of sins in hatred. We must not allow our freedom to protest, to degenerate into physical violence. Again and again we must rise to the majestic heights of meeting physical force for soul force. The marvelous new militancy which has engulfed the Negro community must not lead us to a distrust of all white people. For many of our white folks has evidenced by their presidency of today and come to realize that that's it for your life. They have come to realize that our freedom is in a strict of their thumbs to our freedom. We cannot walk alone. As we walk we must make the pledge that we shall always march ahead. We cannot turn back. There are those who are asking the devotees of civil rights. When will you be satisfied? We can never be satisfied as long as the Negro is a big pick of all the unspeakable horrors of police brutality. We can never be satisfied. As long as our body is hidden with a particular travel, they're not gain marching in the motels of a highway than the hotels of the city. We cannot be satisfied as long as the Negro in Mississippi cannot vote and the Negro in New York believes he has nothing for which to vote. No, no, we are not satisfied and we will not be satisfied until justice rolls down like waters and righteousness like a mighty street. I am not my unmindful that some of you have come here out of great trials and tribulations. Some of you have come fresh from narrow jail sales. Some of you have come from areas where your quest for freedom left you battered by the storms of persecution and staggered by the winds of police brutality. You have been the veterans of creative suffering and continue to work with the faith that unearned suffering is redemptive. Go back to Mississippi. Go back to Alabama. Go back to South Carolina. Go back to Georgia. Go back to Louisiana. Go back to the slums and get those of our northern cities. Knowing that somehow this situation can and will be changed. Let us not wallow in the valley of despair. I say to you today my friends. So even though we face the difficulties of today and tomorrow, I still have a dream. It is a dream deeply rooted in the American dream. I have a dream that one day this nation will rise up and live out the true meaning of its creed. We hold these truths to be self-evident that all men are created each year. I have a dream that one day on the red hills of Georgia, the sons of former slaves and the sons of former slave owners will be able to sit down together at the table of brotherhood. I have a dream that one day even the state of Mississippi of state sweltering with the heat of injustice, sweltering with the heat of oppression will be transformed into an oasis of freedom and justice. I have a dream that my four little children will one day live in a nation where they will not be judged by the color of their skin but by the content of their character. I have a dream today. I have a dream that one day in Alabama with its vicious racists, with its governor having his lips dripping with the words of interposition and nullification. One day right now in Alabama, little black boys and black girls will be able to join hands with little white boys and white girls as sisters and brothers. I have a dream today. I have a dream that one day every valley shall be exalted. Every hill in mountains shall be made, low the rough places will be made plain and the crooked places will be made straight and the go of the Lord shall be revealed and all flesh shall see it together. This is our hope. This is the faith that I go back to the South with, with this faith. We will be able to hue out of the mountain of despair, a stone of hope. With this faith, we will be able to transform the jangling discards of our nation into a beautiful symphony of brotherhood. With this faith, we will be able to work together, to pray together, to struggle together, to go to jail together, to stand up for freedom together, knowing that we will be free one day. This will be the day. This will be the day when all of God's children will be able to sing with new meaning, my country tears are thee. Sweet land of liberty of the I sing, land where my father's died, land of the pilgrim's pride from every mountainside. Let freedom ring in America's to be a great nation. This must become true. So let freedom ring from the prodigious hilltops of New Hampshire. Let freedom ring from the mighty mountains of New York. Let freedom ring from the heightening alligators of Pennsylvania. Let freedom ring from the snow caprockets of Colorado. Let freedom ring from the curvaceous slopes of California. But not only that, let freedom ring from stone mountain of Georgia. Let freedom ring from lookout mountain of Tennessee. Let freedom ring from every hill and low hill of Mississippi from every mountainside. Let freedom ring and when this happens, when we allow freedom ring, when we let it ring from every village and every hamlet, from every state and every city, we will be able to speed up that day when all of God's children, black men and white men, Jews and Gentiles, Protestants and Catholics will be able to join hands and sing in the words of the old Negro spiritual. Pre-at last, pre-at last, thank God Almighty, we are pre-at last.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## I want to transcribe my own voice!\n",
        "\n"
      ],
      "metadata": {
        "id": "KLnDc2G5_e9j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There's a company called huggingface that host certain types of AI model and application. They are based out of Brooklyn, NY; they have never made a profit; they give away almost everything they do; and for this they have received more than [USD$160m in funding](https://www.crunchbase.com/organization/hugging-face). There are good reasons why I think they are worth this money, though! And mostly they are physicists by training, which is interesting *and* explains a lot about how they work.\n",
        "\n",
        "The kind folks at huggingface host the whisper models so you can try them yourself with your own speech:\n",
        "* [English base model](https://huggingface.co/openai/whisper-base.en)\n",
        "* [Multilingual medium model](https://huggingface.co/openai/whisper-medium)\n",
        "* [Multilingual large model](https://huggingface.co/openai/whisper-large)"
      ],
      "metadata": {
        "id": "Xep-AnYnEKMB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Show Me More!\n",
        "\n"
      ],
      "metadata": {
        "id": "Ex83SRjd8rOW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you like Whisper, we have some other great resources coming up for you!\n",
        "* If you have *video*, we can add pose detection and person tracking.\n",
        "* For the *audio*, we can add extraction of acoustic/prosodic features.\n",
        "* Once you have a *transcript*, we can add NLP to identify sentiment, named entities, and more."
      ],
      "metadata": {
        "id": "KjEcCgOWEG8w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Tax"
      ],
      "metadata": {
        "id": "euIkbM8eFVd5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you use Whisper, please **let us know**. We want to work with you! We want to know what works and what doesn't! We want to understand your joys and your concerns."
      ],
      "metadata": {
        "id": "TgrUKZymFW-3"
      }
    }
  ]
}