{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1EU96fZSc90eyRlYRvsNo7a1V3XjHEtzw","timestamp":1681490425091}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Five Minutes with AI: Speech Analysis with Praat"],"metadata":{"id":"iV1rkGXv-3Ll"}},{"cell_type":"markdown","source":["This week, we will use Praat to analyze speech data. [Praat](https://www.fon.hum.uva.nl/praat/) is a software that allows extracting phonetic information about speech using a computer. It has an app with user interface and many functionalities. \n"],"metadata":{"id":"J9CmMrZb7Ovg"}},{"cell_type":"markdown","source":["## What do we like about Praat?\n","\n","* It is very easy to use. One can dowload the app from here and anlayze audio files within minutes.\n","* It provides basic features such as pitch (loudness), speaking rate (number of syllables), pauses along with advanced features such labeling and segmentation."],"metadata":{"id":"vlHdBmZvyeXT"}},{"cell_type":"markdown","source":["## What we don't like about Praat?\n","\n","* Analyzing large number of audio files using praat require you to choose some parameters. "],"metadata":{"id":"4z-DfADOzNGL"}},{"cell_type":"markdown","source":["By using the package [Parselmouth](https://parselmouth.readthedocs.io/en/stable/), we can use praat through python which helps to analyze large number of audio files."],"metadata":{"id":"5cUQxH14z40n"}},{"cell_type":"markdown","source":["## First, let's install the package"],"metadata":{"id":"-c16skLN_JqG"}},{"cell_type":"code","source":["!pip install praat-parselmouth"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4nnXfXP_yKtN","executionInfo":{"status":"ok","timestamp":1681912300145,"user_tz":240,"elapsed":11214,"user":{"displayName":"Tahiya Chowdhury","userId":"02131302661069365744"}},"outputId":"995a099c-4c7f-430a-ac90-934e54b2fb5c"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting praat-parselmouth\n","  Downloading praat_parselmouth-0.4.3-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (10.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.7/10.7 MB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.9/dist-packages (from praat-parselmouth) (1.22.4)\n","Installing collected packages: praat-parselmouth\n","Successfully installed praat-parselmouth-0.4.3\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RQRtLXi2-w33","executionInfo":{"status":"ok","timestamp":1681912316822,"user_tz":240,"elapsed":11154,"user":{"displayName":"Tahiya Chowdhury","userId":"02131302661069365744"}},"outputId":"105bf801-9d06-45ce-afbc-dbb95e7c2384"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: praat-parselmouth in /usr/local/lib/python3.9/dist-packages (0.4.3)\n","Requirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.9/dist-packages (from praat-parselmouth) (1.22.4)\n"]}],"source":["import sys\n","!{sys.executable} -m pip install praat-parselmouth\n","import os\n","import csv\n","import subprocess\n","import parselmouth\n","from glob import glob\n","from parselmouth.praat import call\n","import math\n","import pandas"]},{"cell_type":"markdown","source":["## This is a codeblock we have written to export the information extracted from audio files into a table for later analysis."],"metadata":{"id":"53Jrc_bI_d7f"}},{"cell_type":"code","source":["def speech_rate(filename, silencedb = -25, mindip = 2, minpause = 0.3):\n","    '''\n","    The following code has been adapted from https://osf.io/r8jau to use parcel mouth to extract speaking rate\n","    '''\n","    sound = parselmouth.Sound(filename)\n","    originaldur = sound.get_total_duration()\n","    intensity = sound.to_intensity(50)\n","    start = call(intensity, \"Get time from frame number\", 1)\n","    nframes = call(intensity, \"Get number of frames\")\n","    end = call(intensity, \"Get time from frame number\", nframes)\n","    min_intensity = call(intensity, \"Get minimum\", 0, 0, \"Parabolic\")\n","    max_intensity = call(intensity, \"Get maximum\", 0, 0, \"Parabolic\")\n","\n","    # get .99 quantile to get maximum (without influence of non-speech sound bursts)\n","    max_99_intensity = call(intensity, \"Get quantile\", 0, 0, 0.99)\n","\n","    # estimate Intensity threshold\n","    threshold = max_99_intensity + silencedb\n","    threshold2 = max_intensity - max_99_intensity\n","    threshold3 = silencedb - threshold2\n","    if threshold < min_intensity:\n","        threshold = min_intensity\n","\n","    # get pauses (silences) and speakingtime\n","    textgrid = call(intensity, \"To TextGrid (silences)\", threshold3, minpause, 0.1, \"silent\", \"sounding\")\n","    silencetier = call(textgrid, \"Extract tier\", 1)\n","    silencetable = call(silencetier, \"Down to TableOfReal\", \"sounding\")\n","    npauses = call(silencetable, \"Get number of rows\")\n","    speakingtot = 0\n","    for ipause in range(npauses):\n","        pause = ipause + 1\n","        beginsound = call(silencetable, \"Get value\", pause, 1)\n","        endsound = call(silencetable, \"Get value\", pause, 2)\n","        speakingdur = endsound - beginsound\n","        speakingtot += speakingdur\n","\n","    intensity_matrix = call(intensity, \"Down to Matrix\")\n","    sound_from_intensity_matrix = call(intensity_matrix, \"To Sound (slice)\", 1)\n","    # use total duration, not end time, to find out duration of intdur (intensity_duration)\n","    # in order to allow nonzero starting times.\n","    intensity_duration = call(sound_from_intensity_matrix, \"Get total duration\")\n","    intensity_max = call(sound_from_intensity_matrix, \"Get maximum\", 0, 0, \"Parabolic\")\n","    point_process = call(sound_from_intensity_matrix, \"To PointProcess (extrema)\", \"Left\", \"yes\", \"no\", \"Sinc70\")\n","    # estimate peak positions (all peaks)\n","    numpeaks = call(point_process, \"Get number of points\")\n","    t = [call(point_process, \"Get time from index\", i + 1) for i in range(numpeaks)]\n","\n","    # fill array with intensity values\n","    timepeaks = []\n","    peakcount = 0\n","    intensities = []\n","    for i in range(numpeaks):\n","        value = call(sound_from_intensity_matrix, \"Get value at time\", t[i], \"Cubic\")\n","        if value > threshold:\n","            peakcount += 1\n","            intensities.append(value)\n","            timepeaks.append(t[i])\n","\n","    # fill array with valid peaks: only intensity values if preceding\n","    # dip in intensity is greater than mindip\n","    validpeakcount = 0\n","    currenttime = timepeaks[0]\n","    currentint = intensities[0]\n","    validtime = []\n","\n","    for p in range(peakcount - 1):\n","        following = p + 1\n","        followingtime = timepeaks[p + 1]\n","        dip = call(intensity, \"Get minimum\", currenttime, timepeaks[p + 1], \"None\")\n","        diffint = abs(currentint - dip)\n","        if diffint > mindip:\n","            validpeakcount += 1\n","            validtime.append(timepeaks[p])\n","        currenttime = timepeaks[following]\n","        currentint = call(intensity, \"Get value at time\", timepeaks[following], \"Cubic\")\n","\n","    # Look for only voiced parts\n","    pitch = sound.to_pitch_ac(0.02, 30, 4, False, 0.03, 0.25, 0.01, 0.35, 0.25, 450)\n","    voicedcount = 0\n","    voicedpeak = []\n","\n","    for time in range(validpeakcount):\n","        querytime = validtime[time]\n","        whichinterval = call(textgrid, \"Get interval at time\", 1, querytime)\n","        whichlabel = call(textgrid, \"Get label of interval\", 1, whichinterval)\n","        value = pitch.get_value_at_time(querytime) \n","        if not math.isnan(value):\n","            if whichlabel == \"sounding\":\n","                voicedcount += 1\n","                voicedpeak.append(validtime[time])\n","\n","    # calculate time correction due to shift in time for Sound object versus\n","    # intensity object\n","    timecorrection = originaldur / intensity_duration\n","\n","    # Insert voiced peaks in TextGrid\n","    call(textgrid, \"Insert point tier\", 1, \"syllables\")\n","    for i in range(len(voicedpeak)):\n","        position = (voicedpeak[i] * timecorrection)\n","        call(textgrid, \"Insert point\", 1, position, \"\")\n","\n","    # return results\n","    speakingrate = voicedcount / originaldur\n","    articulationrate = voicedcount / speakingtot\n","    npause = npauses - 1\n","    speechrate_dictionary = {'soundname':filename, \n","                             'nsyll':voicedcount,\n","                             'npause': npause,\n","                             'dur(s)':originaldur,\n","                             'phonationtime(s)':intensity_duration,\n","                             'speechrate(nsyll / dur)': speakingrate,\n","                             \"articulation rate(nsyll / phonationtime)\":articulationrate}\n","    return speechrate_dictionary"],"metadata":{"id":"5FXvKMnM-5RV","executionInfo":{"status":"ok","timestamp":1681912847282,"user_tz":240,"elapsed":146,"user":{"displayName":"Tahiya Chowdhury","userId":"02131302661069365744"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["## Let's run this on a .wav file.\n","\n","#### write the name of your file below. For example, if your file is called \"relaxing_rainsound.wav\", then the code should be `file = './drive/MyDrive/relaxing_rainsound.wav'`\n","\n","#### We are using a short snippet from Briish TV game show \"Would I Lie to You\", where celebrities compete to guess the truthfulness of each \n","\n","* Upload your file to google drive folder"],"metadata":{"id":"EljlT5M11djm"}},{"cell_type":"code","source":["file = './drive/MyDrive/Colab Notebooks/s09e08_3.wav'\n","\n","#give your notebook access to google drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"sEyEtvmy1uii","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681913614774,"user_tz":240,"elapsed":885,"user":{"displayName":"Tahiya Chowdhury","userId":"02131302661069365744"}},"outputId":"2774d193-9add-4804-ac31-9523114f4149"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","source":["## Then run the following code, that will:\n","* analyze the audio file with Praat through Parselmouth\n","* print the extracted information to display\n"],"metadata":{"id":"MiQVPxK95JBH"}},{"cell_type":"code","source":["dict = speech_rate(file)\n","#print(\"The raw output of the function is: \\n\")\n","#print(dict , '\\n')\n","#print(\"Let's break that down: \\n\")\n","print(\"The name of the file / soundname is :\", dict[\"soundname\"])\n","print(\"The number of syllables is: \", dict[\"nsyll\"])\n","print(\"The number of pauses in the file is: \", dict[\"npause\"])\n","print(\"The duration of the audio file in seconds is: \", dict[\"dur(s)\"])\n","print(\"The amount of time where there is speaking in seconds is: \", dict[\"phonationtime(s)\"])\n","print(\"The speaking rate, or the number of syllables divided by the duration is:\" , dict[\"speechrate(nsyll / dur)\"])\n","print(\"The articulation rate, or the number of syllables divided by the amount of time with speech is: \", dict[\"articulation rate(nsyll / phonationtime)\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_7urDs8S-6-W","executionInfo":{"status":"ok","timestamp":1681913645573,"user_tz":240,"elapsed":464,"user":{"displayName":"Tahiya Chowdhury","userId":"02131302661069365744"}},"outputId":"efd59247-083d-402b-d346-0c4fdacd080a"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["The name of the file / soundname is : ./drive/MyDrive/Colab Notebooks/s09e08_3.wav\n","The number of syllables is:  48\n","The number of pauses in the file is:  2\n","The duration of the audio file in seconds is:  13.795\n","The amount of time where there is speaking in seconds is:  13.795\n","The speaking rate, or the number of syllables divided by the duration is: 3.4795215657847045\n","The articulation rate, or the number of syllables divided by the amount of time with speech is:  4.092246046293533\n"]}]},{"cell_type":"markdown","source":["## If you have a large set of audio files you want to analyze together:\n","\n","### The following function, given the name of the folder containing the files, will provide a summary table with all teh information extracted"],"metadata":{"id":"Ar1j43Cu89xg"}},{"cell_type":"code","source":["def parsel_ext(folder_in, file_out):\n","    '''\n","    Takes in a folder of .wav files, uses parcel mouth and praat to extract speaking rate of each file, writes to csv file\n","    \n","    Inputs:\n","    folder_in -- the name of the folder to read\n","    file_out -- name of csv file to write\n","    \n","    Outputs: \n","    files_lost -- the list of files that the script could not be called on and therefore did not make it to the csv file\n","    writes to file file_out with columns for the associated file name (minus the \".wav\"), speech_rate\n","    '''\n","\n","    with open(file_out+\".csv\", 'w', newline='') as file:\n","\n","        writer = csv.writer(file)\n","        writer.writerow([\"file\", \"nsyll\", \"npause\", \"dur\", \"phone_time\", \"speech_rate\", \"art_rate\"])\n","\n","        files_lost = []\n","\n","        #iterating through all files in a folder\n","        for filename in os.listdir(folder_in):\n","            f = os.path.join(folder_in, filename)\n","            if filename[-4:] == \".wav\" and os.path.isfile(f):\n","\n","                #call parsel mouth script\n","                try:\n","                    temp_dict = speech_rate(f)\n","                    \n","                    writer.writerow([filename[:-4], temp_dict[\"nsyll\"], temp_dict[\"npause\"], temp_dict[\"dur(s)\"], \\\n","                            temp_dict[\"phonationtime(s)\"], temp_dict[\"speechrate(nsyll / dur)\"], temp_dict[\"articulation rate(nsyll / phonationtime)\"]])\n","                except:\n","                    files_lost.append(f)\n","        \n","    return files_lost"],"metadata":{"id":"0Yk4CUJs4Xrg","executionInfo":{"status":"ok","timestamp":1681913764331,"user_tz":240,"elapsed":137,"user":{"displayName":"Tahiya Chowdhury","userId":"02131302661069365744"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["## Let's pass a folder with our files. \n","\n","### You can enter the name of a folder to run the code on. For example, if the folder is called sample_data/test_folder, then type `folder = './drive/MyDrive/test_folder`.\n","\n","### We will use a folder with 4 audio snippets from 'Would I Lie to You' season 9 episode 8."],"metadata":{"id":"MMDrLaRC9sfr"}},{"cell_type":"code","source":["folder = \"./drive/MyDrive/Colab Notebooks/s09e08\""],"metadata":{"id":"Yv2lAEO99i11","executionInfo":{"status":"ok","timestamp":1681914170289,"user_tz":240,"elapsed":145,"user":{"displayName":"Tahiya Chowdhury","userId":"02131302661069365744"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":["Now, we'll call the code to extract the features from all the .wav files in the folder. Run the code below:"],"metadata":{"id":"gqKYug5vAlSW"}},{"cell_type":"code","source":["files_lost = parsel_ext(folder, \"summary\")"],"metadata":{"id":"99RK1NuY-qhj","executionInfo":{"status":"ok","timestamp":1681914444455,"user_tz":240,"elapsed":998,"user":{"displayName":"Tahiya Chowdhury","userId":"02131302661069365744"}}},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":["## Let's look at the result file now as a table."],"metadata":{"id":"dcH3q1w1A83v"}},{"cell_type":"code","source":["print(pandas.read_csv(\"summary.csv\").to_markdown(index=False))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EqVelbXbA72H","executionInfo":{"status":"ok","timestamp":1681914445539,"user_tz":240,"elapsed":4,"user":{"displayName":"Tahiya Chowdhury","userId":"02131302661069365744"}},"outputId":"2aa83a4b-7f9b-44a3-bbcb-968dccc82414"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["| file     |   nsyll |   npause |     dur |   phone_time |   speech_rate |   art_rate |\n","|:---------|--------:|---------:|--------:|-------------:|--------------:|-----------:|\n","| s09e08_1 |      52 |        2 | 18.5233 |      18.5233 |       2.80728 |    3.13298 |\n","| s09e08_3 |      48 |        2 | 13.795  |      13.795  |       3.47952 |    4.09225 |\n","| s09e08_4 |      45 |        3 | 13.9    |      13.9    |       3.23741 |    4.32443 |\n","| s09e08_2 |      26 |        1 |  6.926  |       6.926  |       3.75397 |    4.44672 |\n"]}]},{"cell_type":"markdown","source":["## Debugging\n","If Praat is unable analyze some of the audio files we have in our collection, the following function will tell which files, if any, the program is not able to run on. This usually happens when the file is too short for analysis to be done on it. In such case, you may want to keep track of which files were lost in the analysis and remove it later.\n","\n","The following files were lost when you ran the code on your folder:"],"metadata":{"id":"l68vR94lAwyS"}},{"cell_type":"code","source":["print(files_analyzed)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K8J38oygA2ZT","executionInfo":{"status":"ok","timestamp":1681914448312,"user_tz":240,"elapsed":5,"user":{"displayName":"Tahiya Chowdhury","userId":"02131302661069365744"}},"outputId":"28cb2909-20a2-4231-9857-603c5b8cd000"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["[]\n"]}]},{"cell_type":"markdown","source":["### Which means, in this case all the files were analyzed with Praat!"],"metadata":{"id":"yOa6M_nF6eMU"}},{"cell_type":"markdown","source":["## How are we using Praat?\n","\n","We are using Praat to analyse speech data during conversations for:\n","* deception detection\n","* alignment during a conversation\n","* understanding non-verbal cues when interacting with neuro-divergent children."],"metadata":{"id":"yckTcXpH6v9g"}},{"cell_type":"markdown","source":["## I am curious to know more!\n","\n","If you like Praat-Parselmouth, we have other great resources coming up.\n","* If you have audio, we can introduce you to [Whisper](https://colab.research.google.com/drive/1yAHySBUs6W5GRrJfg4IrSrDn-tAeMCE1?usp=sharing) to get the transcript.\n","* If you have *face video*, we can introduce you to facial expression ana landmark analysis with [Pyfeat](https://colab.research.google.com/drive/1lCiTDUp8YHUB9g6UHN4w7W3nZJOCOLUa?usp=sharing).\n","* If you have *fully body video*, we can introduce you to pose detection and person tracking with [OpenPose](https://colab.research.google.com/drive/1PB6sa3PFwT2ag7_7n7KaaUdf7Fj2HxBy?usp=sharing)\n","* For the *audio*, we can add extraction of acoustic/prosodic features.\n","* Once you have a *transcript*, we can add NLP to identify sentiment, named entities, and more."],"metadata":{"id":"TZ3tihJ07GsS"}},{"cell_type":"markdown","source":["## End Note\n","If you use OpnePose, PyFeat, Whisper or Praat, please let us know. We want to work with you! \n","We want to know what works and what doesn't! We want to understand your joys and your concerns."],"metadata":{"id":"ZijNuPAPA4co"}},{"cell_type":"markdown","source":["## Acknowledgement\n","\n","The credit for this tutorial goes to DavisAI RA Meredith Green ('24)."],"metadata":{"id":"cBfnVkZN8r5W"}}]}